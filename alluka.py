# -*- coding: utf-8 -*-
"""alluka.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EztB5t_Q3B-D3mP14NtlRq0Cz4FiHGFI
"""
import re
import shelve
import google.generativeai as genai
import streamlit as st
from twilio.rest import Client

account_sid = 'SEU-ACCOUNT-SID'
auth_token = 'SEU-AUTH-TOKEN'
client = Client(account_sid, auth_token)

# N√∫mero de telefone do remetente (Sandbox)
from_whatsapp_number = "whatsapp:+O-NUMERO-DO-TWILIO"

# N√∫mero de telefone do destinat√°rio (seu n√∫mero de celular cadastrado no Sandbox)
to_whatsapp_number = "whatsapp:+SEU-NUMERO-DE-CELULAR"

st.title("Alluka")
USER_AVATAR = "üë§"
BOT_AVATAR = "ü§ñ"

# Garantir que o gemini_model √© inicializado na session state
if "gemini_model" not in st.session_state:
    st.session_state["gemini_model"] = "gemini-1.0-pro"


# Carregar o chat do arquivo chat_history
def load_chat_history():
    with shelve.open("chat_history") as db:
        return db.get("messages", [])


# Salvar o hist√≥rico do chat
def save_chat_history(messages):
    with shelve.open("chat_history") as db:
        db["messages"] = messages


# Inicializar ou carregar o chat
if "messages" not in st.session_state:
    st.session_state.messages = load_chat_history()

# Barra lateral com bot√£o para deletar o hist√≥rico
with st.sidebar:
    if st.button("Delete Chat History"):
        st.session_state.messages = []
        save_chat_history([])

# Monstrar mensagens do chat
for message in st.session_state.messages:
    avatar = USER_AVATAR if message["role"] == "user" else BOT_AVATAR
    with st.chat_message(message["role"], avatar=avatar):
        st.markdown(message["content"])

# Parametrizando o modelo
GOOGLE_API_KEY = "SUA-API-KEY"
genai.configure(api_key=GOOGLE_API_KEY)
generation_config = {
    "candidate_count": 1,
    "temperature": 0.9
}
safety_settings = {
    "HARASSMENT": "BLOCK_NONE",
    "HATE": "BLOCK_NONE",
    "SEXUAL": "BLOCK_NONE",
    "DANGEROUS": "BLOCK_NONE"
}

# Inicializando o modelo
model = genai.GenerativeModel(model_name="gemini-1.0-pro",
                              generation_config=generation_config,
                              safety_settings=safety_settings)

# Parametrizando o comportamento do modelo.
# Utilizando uma mistura do modelo de redu√ß√£o em partes menores e few-shot prompting
initial_message = """
                     ---
                     Voc√™ √© Alluka uma atendente de disastres naturais e dever√° agir para conseguir da forma mais r√°pida o endere√ßo do civil afetado e prover palavras de conforto caso ele(a) precise.
                     ---
                     Os endere√ßos fornecidos estar√£o localizados no estado do Rio Grande do Sul.
                     Se o civil n√£o digitar o n√∫mero aproxime a localiza√ß√£o para a rua.
                     ---
                     Forne√ßa a latitude e longitude, formate para facilitar o acesso de um programador.
                     ---
                     Endere√ßos n√£o localizados no Rio Grande do Sul n√£o ser√£o utilizados, pe√ßa novamente para que digite o endere√ßo.
                     ---
                     N√ÉO FA√áA UM PRIMEIRO EXEMPLO, PERGUNTE APENAS A LOCALIZA√á√ÉO DO PEDIDO DE SOCORRO
                     ---
                     Pedido de Socorro: Rua dos Andradas, Centro, Porto Alegre.
                     Alluka: Equipe de resgate direcionada para as coordenadas aproximadas [-30.0331, -51.2300].
                     ---
                     Pedido de Socorro: Rua Bento Gon√ßalves, Cidade Baixa, Porto Alegre.
                     Alluka:  Entendido. Resgate a caminho das coordenadas aproximadas [-30.0402, -51.2234].
                     ---
                     Pedido de Socorro: Avenida Borges de Medeiros, Centro, Gramado.
                     Alluka:  Equipe enviada para as coordenadas aproximadas [-29.3764, -50.8751].
                     ---
                     Pedido de Socorro: Rua Garibaldi, Centro Hist√≥rico, Pelotas.
                     Alluka:  Resgate direcionado para [-31.7683, -52.3378].
                     """

chat = model.start_chat(history=[])
# Rodando o chat uma primeira vez para configura√ß√£o o comportamento.
chat.send_message(initial_message)

# Interface principal do chat
if prompt := st.chat_input("Como posso ajudar? "):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar=USER_AVATAR):
        st.markdown(prompt)

    with st.chat_message("assistant", avatar=BOT_AVATAR):
        message_placeholder = st.empty()
        full_response = ""
        response = chat.send_message(prompt)
        message_placeholder.markdown(response.text)
    st.session_state.messages.append({"role": "assistant", "content": response.text})

    response = chat.send_message(prompt)
    response_text = response.text

    # Express√£o regular para encontrar n√∫meros dentro de colchetes
    pattern = r"\[(-?\d+\.\d+), (-?\d+\.\d+)\]"

    match = re.search(pattern, response_text)
    if match:
        latitude = float(match.group(1))
        longitude = float(match.group(2))
        # Crie uma nova mensagem
        message = client.messages.create(
            body=f"**Pessoas precisando de ajuda** \n"
                 f"Latitude: {latitude}, Logintude: {longitude}",
            from_=from_whatsapp_number,
            to=to_whatsapp_number
        )
    else:
        print("Latitude e longitude n√£o encontradas na resposta.")

# Salve o hist√≥rico do chat a cada intera√ß√£o
# save_chat_history(st.session_state.messages)
